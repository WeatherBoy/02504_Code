{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "def load_im(path : str) -> np.ndarray:\n",
    "    \n",
    "    im = cv2.imread(path)[:, :, ::-1]\n",
    "    im = im.astype(np.float64) / 255\n",
    "    \n",
    "    return im\n",
    "\n",
    "\n",
    "def pi(points : np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Converts from homogeneous to inhomogeneous coordinates\n",
    "    \"\"\"\n",
    "    p = points[:-1]/points[-1]\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "def piInv(points : np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Converts from inhomogeneous to homogeneous coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    # Gets the amount of points by using shape\n",
    "    _, num_points = points.shape\n",
    "    \n",
    "    # Stacks the scale s at the bottom of the matrix\n",
    "    ph = np.vstack((points, np.ones(num_points)))\n",
    "    \n",
    "    return ph\n",
    "\n",
    "\n",
    "def projectPoints(K, Rt, Q):\n",
    "    \n",
    "    Q_hom = piInv(Q)\n",
    "    points = K @ Rt @ Q_hom\n",
    "    points_inhom = pi(points)\n",
    "    \n",
    "    return points_inhom\n",
    "\n",
    "\n",
    "def hest(q1, q2) -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Takes two points in 2D and returns the estimated homography matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(q1) != len(q2):\n",
    "        raise ValueError(\"There must be an equal amount of points in the two sets!\")\n",
    "    \n",
    "    Bi = []\n",
    "    for i in range(q1.shape[1]):\n",
    "        qi = q1[:,i]   # <-- getting the first column\n",
    "        \n",
    "        # Creating that weird qx matrix for the Kronecker product\n",
    "        q1x = np.array(\n",
    "            [[0,        -1, qi[1]],\n",
    "             [1,        0, -qi[0]],\n",
    "             [-qi[1], qi[0], 0]]\n",
    "        )\n",
    "        \n",
    "        q2t_hom = q2[:, i].reshape(-1, 1) # <-- getting the first column and reshaping does for dim: (1, ) -> (1,1)\n",
    "        Bi.append(np.kron(q2t_hom.T, q1x)) # <-- formula follows that of week 2, slide 56\n",
    "        # print(np.kron(q2t_hom.T, q1x).shape)\n",
    "       \n",
    "    B = np.concatenate(Bi, axis=0)\n",
    "    \n",
    "    # Some TA prooved that it was unneseccary to find their dot product\n",
    "    #BtB = B.T @ B\n",
    "    V, Lambda, Vt = np.linalg.svd(B)\n",
    "    Ht = Vt[-1, :]\n",
    "    \n",
    "    Ht = np.reshape(Ht, (3, 3))\n",
    "    H = Ht.T\n",
    "    \n",
    "    return H\n",
    "    \n",
    "    \n",
    "def crossOp(p : np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "        One of Them weird functions. It takes in a 3D vector and then returns\n",
    "        some gnarly matrix.\n",
    "    \"\"\"\n",
    "    p = p.flatten()\n",
    "    if p.size != 3:\n",
    "        raise Exception(\"Invalid input, vector must be exactly 3D.\")\n",
    "    \n",
    "    x, y, z = p\n",
    "    px = np.array(\n",
    "        [[0, -z, y],\n",
    "         [z, 0, -x],\n",
    "         [-y, x, 0]]\n",
    "    )\n",
    "    \n",
    "    return px\n",
    "\n",
    "\n",
    "def computeFundamentalMatrix(K1 : np.ndarray, K2 : np.ndarray, R2 : np.ndarray, t2 : np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Computing the fundamental matrix between two camera matrices K1 & K2.\n",
    "    \"\"\"\n",
    "    t2x = crossOp(t2)\n",
    "\n",
    "    E = t2x @ R2\n",
    "\n",
    "    K1inv = np.linalg.inv(K1)\n",
    "    K2inv = np.linalg.inv(K2)\n",
    "\n",
    "    F = K1inv.T @ E @ K2inv\n",
    "    \n",
    "    return F\n",
    "\n",
    "\n",
    "def fancyRotate(theta_x, theta_y, theta_z):\n",
    "    \"\"\"\n",
    "        Does the rotation matrix that we have seen a few times.\n",
    "        E.g. Exercises week 4, eq(12).\n",
    "    \"\"\"\n",
    "    from scipy.spatial.transform import Rotation\n",
    "    \n",
    "    R = Rotation.from_euler(\"xyz\", [theta_x, theta_y, theta_z]).as_matrix()\n",
    "    \n",
    "    return R\n",
    "\n",
    "\n",
    "def triangulate(q_thicc : list, P_thicc : list):\n",
    "    \"\"\"\n",
    "        Should take in:\n",
    "            A list of n pixel-coordinates: [q1, q2, ..., qn]\n",
    "            \n",
    "            A list of n projection matrices: [P1, P2, ..., Pn]\n",
    "        \n",
    "        And return:\n",
    "            The triangulation of the 3D point by utilizing the linear algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(P_thicc)\n",
    "    m = P_thicc[0].shape[1]\n",
    "    \n",
    "    B = np.zeros((2*n, m))\n",
    "    \n",
    "    for i in range(n):\n",
    "        Pi = P_thicc[i]\n",
    "        x, y = q_thicc[i]\n",
    "        x, y = x.item(), y.item()   # <-- apparently there could be some issues with indexing of arrays\n",
    "        \n",
    "        B[i*2] = Pi[2] * x - Pi[0]\n",
    "        B[i * 2 + 1] = Pi[2] * y - Pi[1]\n",
    "        \n",
    "    u, s, vh = np.linalg.svd(B)\n",
    "    v = vh.T\n",
    "    Q = v[:, -1]\n",
    "    \n",
    "    Q = Q.T / Q[-1] # <-- This scaling was highly recommended by Andreas <3\n",
    "    \n",
    "    return Q\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "Its propaply good to remember that:\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        \\pmb{p}_h &= \\pmb{K} \\pmb{P}_{cam}\n",
    "        \\\\\n",
    "        &=  \\pmb{K} \\left[ \\pmb{R} \\pmb{t} \\right] \\pmb{P}_h\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "$$\n",
    "    \\begin{equation*}\n",
    "        \\mathcal{P} = \\pmb{K} \\left[ \\pmb{R} \\pmb{t} \\right]\n",
    "    \\end{equation*}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per usual we have some rotations and translations. They are defined as follows:\n",
    "\n",
    "$$\n",
    "    \\begin{gather*}\n",
    "        \\pmb{R}_1 = \\pmb{R}_2 = \\pmb{I},\n",
    "    \\end{gather*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        \\pmb{t}_1 &=\n",
    "        \\begin{bmatrix}\n",
    "            0 & 0 & 1\n",
    "        \\end{bmatrix}^T\n",
    "        \\\\\n",
    "        \\pmb{t}_2 &=\n",
    "        \\begin{bmatrix}\n",
    "            0 & 0 & 20\n",
    "        \\end{bmatrix}^T\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\begin{gather*}\n",
    "        \\pmb{K}_1 = \\pmb{K}_2 = \n",
    "        \\begin{bmatrix}\n",
    "            700 & 0     & 600 \\\\\n",
    "            0   & 700   & 400 \\\\\n",
    "            0   & 0     & 1\n",
    "        \\end{bmatrix}.\n",
    "    \\end{gather*}\n",
    "$$\n",
    "\n",
    "Where both cameras observe the point:\n",
    "$$\n",
    "    \\begin{gather*}\n",
    "        \\pmb{Q} = \n",
    "        \\begin{bmatrix}\n",
    "            1 & 1 & 0\n",
    "        \\end{bmatrix}^T.\n",
    "    \\end{gather*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "R1 = np.eye(3)\n",
    "R2 = copy.deepcopy(R1)\n",
    "\n",
    "t1 = np.array([0, 0, 1]).reshape(-1, 1)\n",
    "t2 = np.array([0, 0, 20]).reshape(-1, 1)\n",
    "\n",
    "K1 = np.array(\n",
    "    [[700,  0,      600],\n",
    "     [0,    700,    400],\n",
    "     [0,    0,      1]]\n",
    ")\n",
    "\n",
    "K2 = copy.deepcopy(K1)\n",
    "\n",
    "Q = np.array([1, 1, 0]).reshape(-1, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 5.1\n",
    "\n",
    "What are the projectiopn matrices $\\pmb{P}_1$ and $\\pmb{P}_2$?\n",
    "\n",
    "What is the projection of $\\pmb{Q}$ in cameras one and two ($\\pmb{q}_1$ and $\\pmb{q}_2$)?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yields projection matrices: \n",
      "P1\n",
      "[[700.   0. 600. 600.]\n",
      " [  0. 700. 400. 400.]\n",
      " [  0.   0.   1.   1.]] \n",
      "P2\n",
      "[[7.0e+02 0.0e+00 6.0e+02 1.2e+04]\n",
      " [0.0e+00 7.0e+02 4.0e+02 8.0e+03]\n",
      " [0.0e+00 0.0e+00 1.0e+00 2.0e+01]]\n",
      "\n",
      "\n",
      "and the projected points: \n",
      "qs1\n",
      "[[1300.]\n",
      " [1100.]] \n",
      "qs2\n",
      "[[635.]\n",
      " [435.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rt1 = np.concatenate((R1, t1), axis=1)\n",
    "Rt2 = np.concatenate((R2, t2), axis=1)\n",
    "\n",
    "\n",
    "P1 = K1 @ Rt1\n",
    "P2 = K2 @ Rt2\n",
    "\n",
    "qs1 = projectPoints(K1, Rt1, Q)\n",
    "qs2 = projectPoints(K2, Rt2, Q)\n",
    "\n",
    "print(f\"Yields projection matrices: \\nP1\\n{P1} \\nP2\\n{P2}\\n\")\n",
    "print(f\"\\nand the projected points: \\nqs1\\n{qs1} \\nqs2\\n{qs2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 5.2\n",
    "\n",
    "To simulate noise in the detection of points, we add errors to our projections.\n",
    "\n",
    "$$\n",
    "    \\tilde{\\pmb{q}}_1 = \\pmb{q}_1 + [1 - 1]^T, \\quad\n",
    "    \\tilde{\\pmb{q}}_2 = \\pmb{q}_2 + [1 - 1]^T. \n",
    "$$\n",
    "\n",
    "Use your function `triangulate` from week 3 to triangulate $\\pmb{Q}$ from $[\\tilde{\\pmb{q}}_1, \\tilde{\\pmb{q}}_2]$ and $[\\pmb{P}_1, \\pmb{P}_2]$.\n",
    "\n",
    "Take the newly triangulated point $\\tilde{\\pmb{Q}}$ and re-project it to the cameras. How far is it from our observations of the point ($\\tilde{\\pmb{q}_1}, \\tilde{\\pmb{q}_2}$)? In other words, what is the repojection error for each camera?\n",
    "\n",
    "Is this as you expected when recalling the lecture from week?\n",
    "\n",
    "How far is $\\tilde{\\pmb{Q}}$ from $\\pmb{Q}$?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1_approx: \n",
      "[1310.48950027 1089.4923513 ]\n",
      "q2_approx: \n",
      "[635.53411968 434.4839772 ]\n"
     ]
    }
   ],
   "source": [
    "Q_tilde = triangulate([qs1, qs2], [P1, P2])\n",
    "\n",
    "error = np.array([[1,-1]]).T\n",
    "q1_tilde = qs1 + error\n",
    "q2_tilde = qs2 + error\n",
    "Q_tilde = triangulate([q1_tilde, q2_tilde], [P1, P2])\n",
    "\n",
    "q1_appr = pi(P1 @ Q_tilde)\n",
    "q2_appr = pi(P2 @ Q_tilde)\n",
    "\n",
    "# what are the coordinates of the projected points\n",
    "print(f\"q1_approx: \\n{q1_appr}\")\n",
    "print(f\"q2_approx: \\n{q2_appr}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 5.3\n",
    "\n",
    "We are going to make a new function `triangulate_nonlin` that does triangulation using nonlinear optimization. It should take the same inputs as `triangulate`, i.e. a list of *n* pixel coordinates (`q1`, `q2`, . . . , `qn`), and a list of *n* projection matrices (`P1`, `P2`, . . . , `Pn`).\n",
    "\n",
    "Start by defining a helper-function inside `triangulate_nonlin`.\n",
    "\n",
    "(*Don't do that, that's wack. Put the helper function someplace else*).\n",
    "\n",
    "\n",
    "This function, called `compute_residuals`, should take the parameters we want to optimize (in this case $\\pmb{Q}$) as input, and should returns a vector of residuals (i.e. the numbers that we want to minimize the sum of squares of). In this case the residuals are the differences in projection, i.e\n",
    "\n",
    "$$\n",
    "    \\begin{bmatrix}\n",
    "        \\Pi(\\pmb{P}_1 \\pmb{Q}_h) - \\tilde{\\pmb{q}}_1\n",
    "        \\\\\n",
    "        \\Pi(\\pmb{P}_2 \\pmb{Q}_h) - \\tilde{\\pmb{q}}_2\n",
    "        \\\\\n",
    "        \\vdots\n",
    "        \\\\\n",
    "        \\Pi(\\pmb{P}_n \\pmb{Q}_h) - \\tilde{\\pmb{q}}_n\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Call `triangulate` inside your function to get an initial guess `x0` and use `scipy.optimize.least_squares(compute_residuals, x0)` to do least squares optimization, starting from the initial guess of your linear algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 5.4\n",
    "\n",
    "Use `triangulate_nonlin` with $[\\tilde{\\pmb{q}}_1, \\tilde{\\pmb{q}}_2]$ and $[\\pmb{P}_1, \\pmb{P}_2]$.\n",
    "\n",
    "Let us call the nonlinearly estimated point $\\tilde{\\pmb{Q}}$.\n",
    "\n",
    "What is the reprojection error of $\\hat{\\pmb{Q}}$ to camera 1 and 2?\n",
    "\n",
    "How far is $\\hat{\\pmb{Q}}$ from $\\pmb{Q}$.\n",
    "\n",
    "Is this an improvement over the results in *Exercise 5.2*?\n",
    "\n",
    "Congratulations! You now have a useful function that does not currently exist in OpenCV!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera calibration with OpenCV\n",
    "\n",
    "In the following exercises you will be calibrating your own camera. For this we suggest using a camera in your phone or similar.\n",
    "\n",
    "If you have a phone with a wide angle camera, consider using this camera for the exercise (as more lens distortion is more fun and challenging). Remember to disable lens correction in your camera app before taking the pictures.\n",
    "\n",
    "If you get stuck with the OpenCV functions, start by looking it up in the [OpenCV documentation](https://docs.opencv.org/4.x/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 5.5\n",
    "\n",
    "Take one of the provided calibration targets or print your own. If you do not have access to a printer, showing the target on a laptop or tablet display is also an option, albeit less ideal due to the glass on top of the display, which can cause reflection and refraction.\n",
    "\n",
    "Using your calibration target, take pictures of it from many different angles. Make sure to have an image of it straight on and well lit, and try more extreme angles as well. Try to get every part of the frame covered. You should have around **twenty** (20) **images**.\n",
    "\n",
    "Be aware that most phones rotate the image to make it appear correctly on a computer (portrait or landscape). Therefore, try to hold the phone so it rotates all images in the same way during capture."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 5.6\n",
    "\n",
    "Transfer the images to your computer and load them into Python.\n",
    "\n",
    "Check that all images have the same dimensions, to see if it has rotated some of them inadvertently, and discard these images.\n",
    "\n",
    "Why is it a problem for the camera calibration if two images are rotated(in software) differently\n",
    "by the camera (for example portrait and landscape)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 5.7\n",
    "\n",
    "Now, let’s detect checkerboards in your images. Use the function `cv2.findChessboardCorners`.\n",
    "\n",
    "Start with the image where the checkerboard is seen straight on and resize the image to a smaller\n",
    "resolution\n",
    "\n",
    "`im_small = cv2.resize(im, None, fx=0.25, fy=0.25)`\n",
    "\n",
    "Be aware that the function needs the number of internal corners on the checkerboard as input not the total size of the checkerboard. Use the small version of the image to figure out which combination of arguments wants as input (as the function for detecting corners takes a long time if it can’t find corners in a high resolution image).\n",
    "\n",
    "Run `cv2.findChessboardCorners` on all of your images.\n",
    "\n",
    "Is it able to detect checkerboards in all images? If you have a too extreme angle on some images, or there is part of the checkerboard outside the image, the detection function may fail. Use the images it was able to successfully detect checkerboards in, and continue to the next exercise.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 5.8\n",
    "\n",
    "Now it’s time to calibrate the camera!\n",
    "\n",
    "Use `checkerboard_points(n, m)` from last week to construct the points on the checkerboard in 3D, and either use your own function `calibratecamera(qs, Q)` or the one from OpenCV\n",
    "`cv2.calibrateCamera` to calibrate the camera.\n",
    "\n",
    "If you use the OpenCV function, make sure to set the flags argument to not have any lens distortion initially (feel free to add it later).\n",
    "\n",
    "```\n",
    "    flags = cv2.CALIB_FIX_K1+cv2.CALIB_FIX_K2+cv2.CALIB_FIX_K3+cv2.CALIB_FIX_K4+\n",
    "    \n",
    "    cv2.CALIB_FIX_K5+cv2.CALIB_FIX_K6+cv2.CALIB_ZERO_TANGENT_DIST\n",
    "```\n",
    "\n",
    "Inspect the $\\pmb{K}$ matrix. Is the principal point approximately in the center of your images?\n",
    "\n",
    "*Tip*: Make sure that the order of points from `checkerboard_points(n, m)` matches with the order that they are returned by `cv2.findChessboardCorners`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 5.9\n",
    "\n",
    "Reproject the checkerboard corners to the images. You can use your `projectpoints` function from week 2.\n",
    "\n",
    "*Tip*: `cv2.calibrateCamera` returns `rvecs`, which are the $\\pmb{R}$ matrices stored in axis-angle repre-\n",
    "sentation. You can convert them to rotation matrices with `cv2.Rodrigues`.\n",
    "\n",
    "Compute the reprojection error for each frame. Find the frame with the highest reprojection error and show both the detected and reprojected corner points on top of the original image. Your RMSE should not be more than a few pixels.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 5.10\n",
    "\n",
    "Using the `box3d` function from week 1, create a new set of points like so\n",
    "\n",
    "`Q = 2*box3d() + 1`\n",
    "\n",
    "For one of your pictures, use the estimated $\\pmb{R}$ and $\\pmb{t}$ to project these points to the image and visualize the result.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 5.11\n",
    "\n",
    "Do the camera calibration again, this time allowing the first order distortion coefficient $k1$.\n",
    "\n",
    "Do you get a lower reprojection error?\n",
    "\n",
    "If your camera has visible lens distortion, try using the function from week 2 to undistort one of your images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d96a798051220adb8d47ede7819712d4980d7e1ecee887457e300fc8d0177c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
